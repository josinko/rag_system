WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.25.72:5000
Press CTRL+C to quit
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:213: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.
  embeddings = OllamaEmbeddings(model="nomic-embed-text")
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:214: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.
  vectorstore = Chroma(
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:280: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.
  llm = Ollama(model="llama3.2", temperature=0.3)
192.168.25.72 - - [27/Nov/2025 19:57:02] "GET /api/status HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 19:57:17] "POST /api/ask HTTP/1.1" 500 -
192.168.25.72 - - [27/Nov/2025 20:15:15] "GET /api/status HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 20:15:22] "POST /api/ask HTTP/1.1" 500 -
192.168.25.72 - - [27/Nov/2025 20:16:01] "GET /api/status HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 20:16:07] "POST /api/ask HTTP/1.1" 500 -
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.25.72:5000
Press CTRL+C to quit
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:213: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaEmbeddings``.
  embeddings = OllamaEmbeddings(model="nomic-embed-text")
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:214: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.
  vectorstore = Chroma(
d:\Work\It\Codes\_GitHub\rag_system\rag_api.py:280: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.
  llm = Ollama(model="llama3.2", temperature=0.3)
192.168.25.72 - - [27/Nov/2025 22:38:52] "GET /api/status HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:39:15] "POST /api/ask HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:39:22] "GET /api/status HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:39:40] "POST /api/ask HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:39:49] "POST /api/ask HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:40:00] "POST /api/ask HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:40:08] "POST /api/ask HTTP/1.1" 200 -
192.168.25.72 - - [27/Nov/2025 22:41:14] "POST /api/ask HTTP/1.1" 200 -
